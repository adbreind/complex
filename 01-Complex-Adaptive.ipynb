{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data-Driven Analysis and Modeling of Complex Adaptive Systems\n",
    "## Improve Your Understanding of Systems and Emergent Behaviors\n",
    "\n",
    "<img src='images/complex-icon.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 1 Plan\n",
    "\n",
    "Intro, schedule, class ops, key topics\n",
    "* What is a complex adaptive system; examples\n",
    "* Demos: How simple composite systems rapidly get hard to predict\n",
    "* Linear and non-linear systems, measurment and the limits of data science predictive methods\n",
    "\n",
    "Rough, Practical Taxonomy of Interacting Elements in a System\n",
    "* Independent items, accumulating independent items\n",
    "* Connected items, accumulating connected items with addition vs. multiplication\n",
    "* Power-law distribution and challenging aspects of life and decision-making with heavy tails\n",
    "\n",
    "Models for Thinking: Networks\n",
    "* Representing connectivity and contagion for data analysis purposes\n",
    "* Tipping-point behavior\n",
    "* Exercise: Simulating network connectivity\n",
    "\n",
    "Models for Thinking: Automata\n",
    "* Simple automata\n",
    "* Exercise: Conway’s Game of Life\n",
    "* Discussion: What can we learn?\n",
    "\n",
    "Applying Complex Systems Modeling\n",
    "* A network model for data analysis of new product adoption\n",
    "* Small-world graphs\n",
    "* Exercise: Real social network data\n",
    "* Bootstrapping a network model\n",
    "* Exercise: Calibrating the model\n",
    "* Exercise: Introducing a competitor's product\n",
    "* Discussion: What can we learn? What can we report to our firm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a complex adaptive system?\n",
    "\n",
    "A complex adaptive system is a system made up of many partially independent elements. These elements can be \"agents\" (such as people or animals) or entirely inanimate (grains of sand).\n",
    "\n",
    "__Let's look at a few examples to make this clearer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> COVID didn’t just impact our health in 2020. COVID brought us toilet paper shortages, free cheese, and, for a while, no Diet Coke. It seemed wild and impossible to predict – but with the right techniques, we could have solved this sooner. For example, data science techniques like network modeling could have warned us: when we stopped driving, carbon dioxide – a fuel production byproduct – would be scarce and cause soft drink shortages. We can test a variety of data and process models that let us experiment with highly-coupled systems, where problems evince “contagion” similar to the virus itself.\n",
    "\n",
    "__Why can we learn from these systems?__\n",
    "\n",
    "Because the surprising and non-linear responses that emerged at all scales (from individuals to geopolitics) are present throughout natural and man-made systems. So many of the dynamics -- and even many of the specific mathematical patterns -- present in one of these systems are also present in many others.\n",
    "\n",
    "More examples include...\n",
    "* Living organisms\n",
    "* Social groups at all scales (e.g., familes, clubs, firms, social movements, town/city/province governments, etc.)\n",
    "* General biological collectives (e.g., ant colonies)\n",
    "* Avalanches, earthquakes, and traffic jams\n",
    "* Economies and financial markets\n",
    "* Trade and conflict networks\n",
    "* Sociotechnical constructs (e.g., power grid, transportation or communication infrastructure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A quick exercise/demo on the emergence of complex patterns from simple interactions__\n",
    "\n",
    "1. Click the __up__ (^) affordance to add a bit to the rabbit population\n",
    "1. Observe the regular oscillation of rabbit and fox populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://ncase.me/loopy/v1.1/?embed=1&data=[[[1,274,356,0.66,%22rabbits%22,0],[2,710,357,0.66,%22foxes%22,1]],[[2,1,153,-1,0],[1,2,160,1,0]],[[489,369,%22A%2520basic%2520ecological%250Afeedback%2520loop.%250A%250ATry%2520adding%2520extra%250Acreatures%2520to%2520this%250Aecosystem!%22],[489,162,%22more%2520rabbits%2520means%2520MORE%2520foxes%253A%250Ait's%2520a%2520positive%2520(%252B)%2520relationship%22],[498,566,%22more%2520foxes%2520means%2520FEWER%2520rabbits%253A%250Ait's%2520a%2520negative%2520(%25E2%2580%2593)%2520relationship%22]],2%5D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x19d3433d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "url = \"https://ncase.me/loopy/v1.1/?embed=1&data=[[[1,274,356,0.66,%22rabbits%22,0],[2,710,357,0.66,%22foxes%22,1]],[[2,1,153,-1,0],[1,2,160,1,0]],[[489,369,%22A%2520basic%2520ecological%250Afeedback%2520loop.%250A%250ATry%2520adding%2520extra%250Acreatures%2520to%2520this%250Aecosystem!%22],[489,162,%22more%2520rabbits%2520means%2520MORE%2520foxes%253A%250Ait's%2520a%2520positive%2520(%252B)%2520relationship%22],[498,566,%22more%2520foxes%2520means%2520FEWER%2520rabbits%253A%250Ait's%2520a%2520negative%2520(%25E2%2580%2593)%2520relationship%22]],2%5D\"\n",
    "IPython.display.IFrame(url, 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now... let's make this a tiny bit more complex\n",
    "1. Click the \"Remix\" button to open a new tab with this system\n",
    "1. Add a circle above the rabbits and label it \"grass\"\n",
    "1. Create a link from rabbits to grass and under \"relationship\" select \"more -> less\" since more rabbits means less grass\n",
    "1. Create a link from grass back to rabbits and use the \"more -> more\" relationship (since more grass means more rabbits)\n",
    "1. Click __play__ and then __up__ once on the rabbits\n",
    "1. Observe that the population behavior quickly becomes more chaotic\n",
    "\n",
    "Bonus activity: reset the game and this time add a \"coyote\" circle where more rabbits mean more coyotes but more coyotes mean less foxes. Note that this -- and most -- equally simple dynamics get chaotic and unpredictable quickly. \n",
    "\n",
    "Feel free to play around with some of the more complicated scenarious on the LOOPY home page or to create your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's going on here?\n",
    "\n",
    "Even when individual elements of a system exhibit straightforward or predictable behavior, complex and unpredictable behavior can arise from the aggregated interactions of those components.\n",
    "\n",
    "We'll look more precisely at the math in a bit, but the basic idea is that the interactions create an exponential diversity of possibly outcomes and -- even if the system seems to be deterministic -- the limits of our knowledge (or control) of initial conditions makes the system hard to predict or manage very quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The double pendulum system is deterministic -- we know all of the equations that govern its motion. \n",
    "\n",
    "So, in a system like this, can we exert control by setting initial conditions? Often, no. Here are 50 double pendulums whose initial velocities differ by only 1 part in 1 million (*credit to Dillon Berger @InertialObservr!*)\n",
    "\n",
    "Can you control your inputs to within 1 part in 1 million? Even if you could, a simple system like this diverges to a nearly uniform distribution (i.e., every angle has equal probability) in under 20 seconds!\n",
    "\n",
    "<video src='images/million.mp4' controls/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Takeaway: We cannot predict and control these sorts of systems through \"classical\" planning and techniques.__\n",
    "\n",
    "This is why, for example, we understand earthquakes, avalanches, and financial crashes quite well. We can even predict them probabilistically (i.e., identify their frequency-magnitude patterns). But we can't predict any individual occurrence.\n",
    "\n",
    "__The behavior of complex systems lies on the boundary between (simple) order and chaos.__\n",
    "\n",
    "One way to make sense of that phenomenon is to think about how strongly the elements in a system are coupled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A rough, practical taxonomy for thinking about interactions in a system\n",
    "\n",
    "The simplest compound systems we deal with include __independent items__\n",
    "\n",
    "This independency assumption, we'll see, is key to knowing where the complexity may be lurking.\n",
    "\n",
    "#### Accumulating independent items by addition: the Gaussian (normal) distribution\n",
    "\n",
    "The Gaussian distribution underlies many of our tools and techniques. And we have great ability to manage systems that follow Gaussian distributions. For example, the Gaussian underlies modern statistical process control, six-sigma, and other quality and risk management techniques.\n",
    "\n",
    "We'd like it to apply everywhere, but it doesn't apply everywhere. So when *does* it work?\n",
    "\n",
    "__The Gaussian describes accumulation of independent items__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.uniform(low=0, high=2, size=(1000, 1000))\n",
    "\n",
    "sums = samples.sum(axis=0)\n",
    "\n",
    "sns.displot(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Examples for the Gaussian__\n",
    "\n",
    "Primary\n",
    "* Human height is a result of dozens of genes affecting different aspects of growth\n",
    "* Most of these genes can be inherited and operate independently\n",
    "* Heights show a Gaussian distribution\n",
    "\n",
    "Secondary\n",
    "* Grocery stores like to stock popular products at eye level (\"eye level is buy level\")\n",
    "* Since heights are normally distributed, the stocking of shelves follows that normal distribution\n",
    "* Of course, the other shelves are not empty -- they just have items lower on the merchant's \"sale priority\"\n",
    "\n",
    "Workers in many disciplines have assumed the Gaussian holds where it does not, with disastrous consequences. \n",
    "\n",
    "Why do they use it? One reason is because it's easy to work with and well known.\n",
    "\n",
    "Why does it fail? One reason is because the tails of the Gaussian are extremely thin -- i.e., events far away from the mean \"should never\" occur. If they do occur, that's a sign we're using the wrong distribution!\n",
    "\n",
    "* We've had multiple \"hundred-year\" floods or other climate events within a decade...\n",
    "    * That's a hint that the distribution used to model the weather (the one that expects one event per hundred years) is not the proper distribution we're dealing with\n",
    "* Financial crises that \"should never happen\" (SVB collapse, mortgage [\"great financial '08\"] crisis, Long-Term Capital Management collapse, ruble crisis, peso crisis, etc.) keep happening...\n",
    "    * That's a sign that the financial risk modeling folks are not using the right distribution\n",
    "\n",
    "__Extreme events live in the \"tails\" of the distribution, far away from the expectation. But that doesn't mean they are unlikely. It all depends on the thickness of those tails.__\n",
    "\n",
    "#### Accumulating independent items by multiplication: the Log-normal distribution\n",
    "\n",
    "Because multiplying items is the same as adding them in log-space, when many independent items are multiplied, we get a distribution whose log is normal. It's called the log-normal distribution and looks like this:\n",
    "\n",
    "<img src='images/logn.png' width=500>\n",
    "\n",
    "This distribution requires a little more __caution__ ... it looks a bit like the Gaussian but can have a long, thick right tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.uniform(low=0.95, high=1.05, size=(200, 1000))\n",
    "\n",
    "prod = samples.prod(axis=0)\n",
    "\n",
    "sns.displot(prod, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Examples for the log-normal__\n",
    "\n",
    "Log-normal distributions describe \n",
    "* the sizes of British farms https://academic.oup.com/bioscience/article/51/5/341/243981\n",
    "* milk production by cows https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5567198/\n",
    "* worker pay, when sequences of multiplicative (e.g., +x%) raises are applied\n",
    "\n",
    "Not all log-normal distributions have thick tails (you can play with them interactively at https://distribution-explorer.github.io/continuous/lognormal.html)\n",
    "\n",
    "But be aware of the consequences of a thick tail: large amounts of probability mass far away from the expected values.\n",
    "\n",
    "### What about non-independent items, the ones we see in complex systems?\n",
    "\n",
    "#### Accumulating <span style='color:red'>non-independent</span> items by multiplication: the power-law distribution\n",
    "\n",
    "In many systems, effects are multiplied as they pass (or cycle) throughout the system. \n",
    "\n",
    "When these effects are not independent, they give rise to a dramatically different distribution of values. They yield extremes of inequality, and, in some cases, significant numbers of very extreme events.\n",
    "\n",
    "Box office receipts, book sales, wealth in some countries, frequencies of words, and sizes of power outages all follow power-law distributions for different, but related reasons.\n",
    "\n",
    "These systems often result from feedback loops or network effects giving rise to the \"Matthew effect\" (or \"the rich-get-richer\") https://en.wikipedia.org/wiki/Matthew_effect -- of course, in technology, entrepreneurs seek out exactly these sorts of dynamics in order to get big returns for investors, venture capitalists, and themselves.\n",
    "\n",
    "Let's simulate some app-store sales data to demonstrate this. In this example we'll collect 1000 sets of 50 samples.\n",
    "\n",
    "Within each set, though, the samples won't be independent.\n",
    "\n",
    "* We create a \"window\" (initially 0.03 wide) representing a range of possible sales rates\n",
    "* Start by sampling from a uniform distribution around 1.0, with a width equal to that window\n",
    "* For each subsequent sample within each set, we move the window so that it's centered on the previous sample\n",
    "    * This simulates a network effect where a higher draw in one round allows for a slightly higher range to sample in the next round\n",
    "    * We adjust to prohibit the window from going below 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "samples = np.zeros((50, 1000)) # rows are (50) sequence steps of aggregate return; columns will be indepentent samples (1000)\n",
    "\n",
    "half_range_width = 0.015 \n",
    "# all values will start within this distance of 1.0, and at each time step experience returns within this range of 1.0\n",
    "\n",
    "samples[0, :] = np.random.uniform(low=1-half_range_width, high=1+half_range_width, size=(1, 1000))\n",
    "\n",
    "for sample in range(1000):\n",
    "    for step in range(1, 50):\n",
    "        prev = samples[step-1, sample] \n",
    "        low = max(prev - half_range_width, 0) # new possibility range adjusted up/down based on previous value\n",
    "        high = 2*half_range_width if low == 0 else prev + half_range_width        \n",
    "        samples[step, sample] = random.random() * (high - low) + low\n",
    "\n",
    "# that loop can be parallelized better w numpy, but I wanted to make the algorithm extra explicit\n",
    "        \n",
    "result = samples.prod(axis=0)\n",
    "sns.displot(result, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice some of the extreme results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result < .25).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result > 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result > 25).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The luckiest folks are *really* doing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result < result.mean()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 80% end up worse than the average.\n",
    "\n",
    "Some fat-tailed distributions are even more extreme -- so extreme in fact that they have no expected value (mean) at all (https://rviews.rstudio.com/2017/02/15/some-notes-on-the-cauchy-distribution/)\n",
    "\n",
    "__Nassim Nicholas Taleb__, of \"Black Swan\" fame, has made a career of explaining and investing in these extreme occurrences. He calls systems that have substantial mass in the tail \"Extremistan\" and cautions against making assumptions based on the events we frequently see or have seen historically.\n",
    "\n",
    "In many of these distributions, there will always be more extreme (in degree) events (and more of them in quantity) than we have ever seen in the past. We simply can't predict anything except that, sooner or later, they do occur.\n",
    "\n",
    "In the political and cultural domain, many researchers believe these distributions characterize probabilities and severities of\n",
    "* pandemics\n",
    "* stock market crashes\n",
    "* riots and civil unrest\n",
    "* wars and revolutions\n",
    "\n",
    "while in the business world we see\n",
    "* stock market crashes\n",
    "* banking/currency crises\n",
    "* industry sector disruptions and transformations\n",
    "    * these can be positive (e.g., Internet, mobile) as well as negative\n",
    "    \n",
    "These can sometimes be described as tipping points or phase changes. Systems that tend to organize themselves into states close to tipping points are said to exhibit *self-organizing criticality*.\n",
    "\n",
    "__Whenever we see a system characterized by interrelated and interacting (not independent) multiplicative effects, we need to pay close attention__. For some systems, under some limited conditions, we can model the distribution based on information we have (https://en.wikipedia.org/wiki/Extreme_value_theory) but in many cases, there is no way to get a confident description of the tails based on the data we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Checkpoint__\n",
    "\n",
    "At this point, we've gotten a high-level feel for one way of thinking about the emergence of complex or sometimes chaotic behavior.\n",
    "\n",
    "You should feel like there is a bit of statistical logic which underlies less predictable, as opposed to more predictable, systems and events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
